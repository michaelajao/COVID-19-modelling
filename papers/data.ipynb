{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from uk_covid19 import Cov19API\n",
    "\n",
    "min_confirmed = 5\n",
    "days_ran = 250\n",
    "days_predicted = 20\n",
    "\n",
    "\n",
    "class LoadData:\n",
    "    @staticmethod\n",
    "    def getUkdf() -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        get the data from Nhs api\n",
    "        These should return a dataframe\n",
    "        \"\"\"\n",
    "\n",
    "        all_nations = [\"areaType=utla\"]\n",
    "\n",
    "        cases_and_deaths = {\n",
    "            \"date\": \"date\",\n",
    "            \"areaName\": \"areaName\",\n",
    "            \"dailyCases\": \"newCasesByPublishDate\",\n",
    "            \"dailyDeaths\": \"newDeaths28DaysByPublishDate\",\n",
    "            \"cumulativeCases\": \"cumCasesByPublishDate\",\n",
    "        }\n",
    "\n",
    "        api = Cov19API(filters=all_nations, structure=cases_and_deaths)\n",
    "\n",
    "        df = api.get_dataframe()\n",
    "\n",
    "        # df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.date\n",
    "        # df_uk = df[df.daily > min_confirmed]\n",
    "        # df_uk[\"day\"] = df_uk.date.apply(\n",
    "        #     lambda x: (x-df_uk.date.min()).days\n",
    "        # )\n",
    "        # df_uk = df_uk.reset_index()\n",
    "\n",
    "        # if retain == True:\n",
    "        #     lastdate = str(df_uk.date.iloc[-1])\n",
    "        #     df_uk.to_csv(lastdate + \"_uk_by_day.csv\", index=False)\n",
    "\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.date\n",
    "        df.fillna(\n",
    "            value={\"dailyDeaths\": 0, \"cumulativeCases\": 0},\n",
    "            inplace=True,\n",
    "            downcast=\"int64\",\n",
    "        )\n",
    "        df = df[df.dailyCases > min_confirmed]\n",
    "        df[\"day\"] = df.date.apply(lambda x: (x - df.date.min()).days)\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def getcitiesDF(df: pd.DataFrame, city_name: str) -> pd.DataFrame:\n",
    "        \"\"\"[Get updated data on the epidemic of a specific city by day in the uk]\n",
    "        Args:\n",
    "            df ([type: datframe]): [The resulting Data returned from the covid19 uk data api]\n",
    "            city_name (str): [the name of the city that should be passed]\n",
    "        Returns:\n",
    "            pd.DataFrame: [covid-19 cumulative data of daily confirmed and death in the uk for a particular city]\n",
    "        \"\"\"\n",
    "\n",
    "        grouped_area = df[df[\"areaName\"] == city_name]\n",
    "        grouped_area_cases = grouped_area.drop(columns=[\"areaName\"])\n",
    "        grouped_area_cases = grouped_area_cases.reset_index(drop=True)\n",
    "        new_df = grouped_area_cases.head(days_ran)\n",
    "\n",
    "        time_data = np.array(new_df.day.values.astype(np.float64))\n",
    "        time_data = time_data - time_data[0]\n",
    "\n",
    "        dailycases = new_df.dailyCases.values.astype(np.float64)\n",
    "        deathcases = np.diff(new_df.dailyDeaths.values.astype(np.float64))\n",
    "        deathcases = np.insert(deathcases, 0, deathcases[0])\n",
    "\n",
    "        original_data = np.array([dailycases, deathcases])\n",
    "\n",
    "        data_dates = new_df.date.values\n",
    "        data_dates = [date.strftime(\"%d/%m/%y\") for date in data_dates]\n",
    "\n",
    "        return original_data, data_dates, time_data\n",
    "\n",
    "    @staticmethod\n",
    "    def getDataJH() -> pd.DataFrame:\n",
    "        # https://gradcoach.com/literature-review-structure/\n",
    "\n",
    "        confirmed_df = pd.read_csv(\n",
    "            \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\"\n",
    "        )\n",
    "        deaths_df = pd.read_csv(\n",
    "            \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv\"\n",
    "        )\n",
    "        recoveries_df = pd.read_csv(\n",
    "            \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv\"\n",
    "        )\n",
    "        # latest_data = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/08-22-2020.csv')\n",
    "        # us_medical_data = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports_us/08-22-2020.csv')\n",
    "\n",
    "        # data_url = requests.get(url).content\n",
    "        # df = pd.read_csv(io.StringIO(data_url.decode(\"utf-8\")))\n",
    "\n",
    "        # confirmed_df = confirmed_df.drop(\n",
    "        #     [\"UID\", \"iso2\", \"iso3\", \"code3\", \"FIPS\", \"Admin2\", \"Combined_Key\"], axis=1\n",
    "        # )\n",
    "        # deaths_df = deaths_df.drop(\n",
    "        #     [\"UID\", \"iso2\", \"iso3\", \"code3\", \"FIPS\", \"Admin2\", \"Combined_Key\"], axis=1\n",
    "        # )\n",
    "        # recoveries_df = recoveries_df.drop(\n",
    "        #     [\"UID\", \"iso2\", \"iso3\", \"code3\", \"FIPS\", \"Admin2\", \"Combined_Key\"], axis=1\n",
    "        # )\n",
    "\n",
    "        columns_rename = {\"Province_State\": \"State\", \"Country_Region\": \"Country\"}\n",
    "        confirmed_df.rename(columns=columns_rename, inplace=True)\n",
    "        deaths_df.rename(columns=columns_rename, inplace=True)\n",
    "        recoveries_df.rename(columns=columns_rename, inplace=True)\n",
    "\n",
    "        confirmed_df = confirmed_df.groupby(by=\"Country\", as_index=False).sum()\n",
    "        deaths_df = deaths_df.groupby(by=\"Country\", as_index=False).sum()\n",
    "        recoveries_df = recoveries_df.groupby(by=\"Country\", as_index=False).sum()\n",
    "\n",
    "        grouped_df = pd.DataFrame(\n",
    "            columns=[\n",
    "                \"date\",\n",
    "                \"State\",\n",
    "                \"Country\",\n",
    "                \"Lat\",\n",
    "                \"Long\",\n",
    "                \"Confirmed\",\n",
    "                \"Deaths\",\n",
    "                \"Recorvered\",\n",
    "            ]\n",
    "        )\n",
    "        grouped_df[\"date\"] = confirmed_df.columns[4:]\n",
    "        grouped_df[\"Confirmed\"] = grouped_df[\"Dates\"].apply(\n",
    "            lambda x: confirmed_df[x].sum()\n",
    "        )\n",
    "        grouped_df[\"Deaths\"] = grouped_df[\"Dates\"].apply(lambda x: deaths_df[x].sum())\n",
    "        grouped_df[\"Recovered\"] = grouped_df[\"Dates\"].apply(\n",
    "            lambda x: recoveries_df[x].sum()\n",
    "        )\n",
    "        grouped_df.reset_index(drop=False, inplace=True)\n",
    "\n",
    "        return grouped_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
